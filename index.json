[{"authors":["admin"],"categories":null,"content":"As of September 2018, I am an assistant professor at the Econometric Institute of the Erasmus University Rotterdam. I became a candidate fellow of the Tinbergen Institute in May 2019.\n","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"598b63dd58b43bce02403646f240cd3c","permalink":"https://hannoreuvers.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"author","summary":"As of September 2018, I am an assistant professor at the Econometric Institute of the Erasmus University Rotterdam. I became a candidate fellow of the Tinbergen Institute in May 2019.","tags":null,"title":"Hanno Reuvers","type":"author"},{"authors":null,"categories":[],"content":"ðŸ“†\n","date":1561201200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561201200,"objectID":"7e3b9ee66ea40d580e55646e62dceeb8","permalink":"https://hannoreuvers.github.io/talk/cyprus/","publishdate":"2019-06-01T00:00:00+02:00","relpermalink":"/talk/cyprus/","section":"talk","summary":"ðŸ“†","tags":[],"title":"6th :heart: RCE Time Series Econometrics Workshop 2019 - Rimini Centre for Economic Analysis","type":"talk"},{"authors":null,"categories":null,"content":"","date":1559340120,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559340120,"objectID":"3fc24b68471bfe346109de27cb0ed637","permalink":"https://hannoreuvers.github.io/publication/lad-paper/","publishdate":"2019-06-01T00:02:00+02:00","relpermalink":"/publication/lad-paper/","section":"publication","summary":"","tags":null,"title":"Inference on VAR Models using Least Absolute Deviations","type":"publication"},{"authors":null,"categories":null,"content":"","date":1559340000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559340000,"objectID":"94432b662be6869e43e108049167b776","permalink":"https://hannoreuvers.github.io/publication/ekc-paper/","publishdate":"2019-06-01T00:00:00+02:00","relpermalink":"/publication/ekc-paper/","section":"publication","summary":"This paper develops the asymptotic theory of a Fully Modified Generalized Least Squares (FMGLS) estimator for multivariate cointegrating polynomial regressions. Such regressions allow for deterministic trends, stochastic trends and integer powers of stochastic trends to enter the cointegrating relations. As such, they are natural extensions of the linear cointegration framework. Our fully modified estimator relies on: (1) the inverse autocovariance matrix of the multidimensional errors, and (2) second order bias corrections. Both quantities are unknown in practice. The inverse autocovariance matrix of the errors is estimated directly using the modified Cholesky decomposition originally proposed by Pourahmadi (1999). The resulting estimator has the intuitive interpretation of applying a weighted least squares objective function to filtered data series. Moreover, the second order bias corrections are convenient byproducts of our approach, hence avoiding the difficult kernel and bandwidth selections that typically accompany long-run covariance estimation. Overall, our feasible FMGLS estimator allows for standard asymptotic inference. Extending earlier work by Phillips and Park (1988), we elaborate on the conditions that make this FMGLS estimator asymptotically equivalent to its ordinary least squares counterpart. We also extend Wagner and Hong (2016) by providing a new residual-based test for cointegrating polynomial regressions. That is, our KPSS type of test does not use the ordinary residuals but the residuals that have been weighted and filtered by their estimated inverse autocovariance matrix. A comprehensive simulation study shows good performance of the FMGLS estimator and the related tests. In comparison to FMOLS, the FMGLS estimator leads to lower MSEs and improved size and power properties in finite samples. Moreover, the cointegration test exhibits similar nontrivial size and power improvements. As a practical illustration, we test the Environmental Kuznets Curve (EKC) hypothesis for six early industrialized countries.","tags":null,"title":"Efficient Estimation by Fully Modified GLS with an Application to the Environmental Kuznets Curve","type":"publication"},{"authors":null,"categories":null,"content":"","date":1551394800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551394800,"objectID":"aed8dd42cafb875117da93f207302cd8","permalink":"https://hannoreuvers.github.io/publication/liege-paper/","publishdate":"2019-03-01T00:00:00+01:00","relpermalink":"/publication/liege-paper/","section":"publication","summary":"Understanding the development of trends and identifying trend reversals in decadal time series is becoming more and more important. Many climatological and atmospheric time series are characterized by autocorrelation, heteroskedasticity and seasonal effects. Additionally, missing observations due to instrument failure or unfavorable measurement conditions are common in such series. This is why it is crucial to apply methods which work reliably under these circumstances. The goal of this paper is to provide a toolbox which can be used to determine the presence and form of changes in trend functions using parametric as well as nonparametric techniques. We consider bootstrap inference on broken linear trends and smoothly varying nonlinear trends. In particular, for the broken trend model, we propose a bootstrap method for inference on the break location and the corresponding changes in slope. For the smooth trend model we construct simultaneous confidence bands around the nonparametrically estimated trend. Our autoregressive wild bootstrap approach combined with a seasonal filter, is able to handle all issues mentioned above. We apply our methods to a set of atmospheric ethane series with a focus on the measurements obtained above the Jungfraujoch in the Swiss Alps. Ethane is the most abundant non-methane hydrocarbon in the Earth's atmosphere, an important precursor of tropospheric ozone and a good indicator of oil and gas production as well as transport. Its monitoring is therefore crucial for the characterization of air quality and of the transport of tropospheric pollution.","tags":null,"title":"Nonparametric estimation and bootstrap inference on trends in atmospheric time series: an application to ethane","type":"publication"},{"authors":[],"categories":null,"content":" Short intro Let us compare the performance of C++, Matlab, Python and R when performing typical econometrical/statistical tasks. The word â€˜typicalâ€™ is quite ambiguous since computational requirements can vary substantially between subfields. As such, I will consider a setting that is standard yet also computationally demanding: bootstrap inference on the Durbin-Watson test statistic. This setting is easy to understand and the computational performance of the programming languages is probably representative for a wide range of Monte Carlo (MC) simulations. MC simulations are very often needed in research when relying on frequentist statistics.\nThe Durbin-Watson test statistic Consider a standard multivariate regression model $y_t^{} = \\mathbf{x}_t\u0026rsquo; \\boldsymbol \\beta + u_t^{}$ for $t = 1, 2, \u0026hellip; , T$. The presence of serial correlation in $u_t$ will render standard ordinary least squares (OLS) inference invalid. The Durbin-Watson test statistic was one of the first test statistics to test for the presence of serial correlation.1 It is computed as follows:\n Calculate the OLS estimator $\\widehat{\\boldsymbol \\beta}=(\\mathbf{X}\u0026rsquo;\\mathbf{X})^{-1} \\mathbf{X}\u0026rsquo;\\mathbf{y}$. Obtain the residuals $\\widehat{u}_t=y_t- \\mathbf{x}_t\u0026rsquo;\\widehat{\\boldsymbol \\beta}$ for $t = 1, 2, \u0026hellip; , T$. The Durbin-Watson test statisic is now computed as $DW= \\frac{\\sum_{t=2}^T \\left(\\widehat{u}_t-\\widehat{u}_{t-1}\\right)^2 }{\\sum_{t=1}^T \\widehat{u}_t^2}$.  Simple algebraic manipulations show that the Durbin-Watson statistic can be expressed in terms of the first order sample autocorrelation $\\widehat{\\rho}= \\frac{\\sum_{t=2}^T \\widehat{u}_t\\widehat{u}_{t-1} }{\\sum_{t=1}^T \\widehat{u}_t^2}$, namely $DW=2(1-\\widehat{\\rho})-\\frac{\\widehat{u}_1^2+\\widehat{u}_T^2}{\\sum_{t=1}^T \\widehat{u}_t^2}$. Based on this result we would expect outcomes close to the value 2 if first order autocorrelation is absent. Values different from 2 indicate serial correlation. Using the Durbin-Watson statistic to carry out a formal hypothesis test is more complicated because its (asymptotic) distribution is difficult to derive. This motivates the use of a bootstrap approach.2 The specific steps are:\n Estimate $\\widehat{\\boldsymbol \\beta}$ and compute the residual series ${\\widehat{u}_t }$ as well as the Durbin-Watson statistic $DW$. Compute $\\widehat{\\rho}$ (see the definition above) and $\\widehat{\\varepsilon\\,}_t=\\widehat{u}_t- \\widehat{\\rho} \\widehat{u}_{t-1}$ for $t=2,3,\\ldots,T$. Draw bootstrap errors $\\varepsilon_t^\\star$ by resampling with replacement from $\\{\\widehat{\\varepsilon\\,}_2,\\widehat{\\varepsilon\\,}_3,\\ldots,\\widehat{\\varepsilon\\,}_T \\}$. Store these in the vector $\\boldsymbol \\varepsilon^\\star=[\\varepsilon_1^\\star,\\varepsilon_2^\\star,\\ldots,\\varepsilon_T^\\star]\u0026rsquo; $. Set $\\mathbf{u}^\\star=\\boldsymbol \\varepsilon^\\star$ (to impose the null hypothesis in the bootstrap sample), construct the bootstrap sample $\\mathbf{y}^\\star=\\mathbf{X}\\widehat{\\boldsymbol \\beta}+$, and compute the DW statistic from $\\mathbf{y}^\\star$. Repeat steps 3-4 $B$ times and store these outcomes in a list $\\left\\{ DW_b^\\star \\right\\}_{b=1}^B$. For a given significance level $\\alpha$, we define $q_{\\alpha/2}^\\star$ and $q_{1-\\alpha/2}^\\star$ as the $\\alpha/2$ and $1-\\alpha/2$ empirical quantiles of $\\left\\{ DW_b^\\star \\right\\}_{b=1}^B$. We reject the null hypothesis of no serial correlation if either $DW \u0026lt; q_{\\alpha/2}^\\star$ or if $DW\u0026gt;q_{1-\\alpha/2}^\\star$.  The simulation setting We consider a simple simulation setting to compare the different programming environments, namely\n$$ \\begin{aligned} y_t \u0026amp;= \\mathbf{x}_t\u0026rsquo;\\boldsymbol{\\beta}+u_t \\\\\nu_t \u0026amp;= \\rho u_{t-1}+\\varepsilon_t, \\qquad \\qquad t=1,2,\\ldots,T, \\end{aligned} $$\nwhere $T=\\{100,250,500\\}$. The fixed regressor matrix $\\mathbf{X}$ contains a column of ones and a column that repeats the sequence $0,1,0,-1$ (orthogonal design). The error terms ${\\epsilon_t}$ are standard normal and a presample of 50 observations is used to remove the influence of the initial values. We set $\\boldsymbol \\beta=[1,2]\u0026rsquo; $ and vary the value for $\\rho$ over the grid $[0,0.025,\\ldots,0.5]\u0026rsquo; $ (21 grid points). The resulting power curves are depicted in Figure 1. Overall, we use 1000 Monte Carlo replications where each replication uses $B=499$ bootstrap resamples.\nResults and discussion Simulations are performed on a Macbook with a 2.6 GHz Intel Core i5 processor. I used serial computing. The computational times are reported in Table 1.\n Table 1: Absolute and relative (using C++ as the benchmark) computational times in seconds.   The conclusions from this table are unambiguous. The C++ implementation is significantly faster than the scientific programming environments of Matlab and R. However, this should be balanced against the fact that the programming itself is much easier/faster in the user-friendly environments offered by either of these languages. The results do not promote the use of Python. The computational times are longest and coding is less comfortable because matrix algebra requires an additional library (such as numpy). My conclusions are qualitatively the same as those in BoraÄŸan Aruoba and FernÃ¡ndez-Villaverde (2015).3\nReferences  J. Durbin and G. S. Watson (1971), Testing for Serial Correlation in Least Squares Regression, Biometrika ^ J. Jeong and S. Chung (2001), Bootstrap Tests for Autocorrelation, Computational Statistics and Data Analysis ^ S. BoraÄŸan Aruoba and J. FernÃ¡ndez-Villaverde (2015), A Comparison of Programming Languages in Macroeconomics, Journal of Economic Dynamics \u0026amp; Control ^   ","date":1527804000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527804000,"objectID":"53ddb2b1af9173dcac5d24d95688dc91","permalink":"https://hannoreuvers.github.io/post/which-language/","publishdate":"2018-06-01T00:00:00+02:00","relpermalink":"/post/which-language/","section":"post","summary":"A comparison of C++, Matlab, Python and R for Monte Carlo simulations","tags":[],"title":"Which computational language to choose?","type":"post"},{"authors":null,"categories":null,"content":"","date":1517439600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517439600,"objectID":"787f64717bdb93c7ad157f67a2916977","permalink":"https://hannoreuvers.github.io/publication/fic-paper/","publishdate":"2018-02-01T00:00:00+01:00","relpermalink":"/publication/fic-paper/","section":"publication","summary":"This paper investigates the focused information criterion and plug-in average for vector autoregressive models with local-to-zero misspecification. These methods have the advantage of focusing on a quantity of interest rather than aiming at overall model fit. Any (suï¬ƒciently regular) function of the parameters can be used as a quantity of interest. We determine the asymptotic properties and elaborate on the role of the locally misspecified parameters. In particular, we show that the inability to consistently estimate locally misspecified parameters translates into suboptimal selection and averaging. We apply this framework to impulse response analysis. A Monte Carlo simulation study supports our claims.","tags":null,"title":"Focused Information Criterion for Locally Misspecified Vector Autoregressive Models","type":"publication"}]